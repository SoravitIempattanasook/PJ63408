{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7f6160f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 720)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "data = pd.read_csv('RandomForest.csv')\n",
    "x = data[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', \n",
    "          'X18', 'X19', 'X20', 'X21', 'X22', 'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32', 'X33',\n",
    "         'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40', 'X41', 'X42', 'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49',\n",
    "         'X50', 'X51', 'X52', 'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60', 'X61', 'X62', 'X63', 'X64', 'X65',\n",
    "         'X66', 'X67', 'X68', 'X69', 'X70', 'X71', 'X72', 'X73', 'X74', 'X75', 'X76', 'X77', 'X78', 'X79', 'X80', 'X81',\n",
    "         'X82', 'X83', 'X84', 'X85', 'X86', 'X87', 'X88', 'X89', 'X90', 'X91', 'X92', 'X93', 'X94', 'X95', 'X96', 'X97',\n",
    "         'X98', 'X99', 'X100', 'X101', 'X102', 'X103', 'X104', 'X105', 'X106', 'X107', 'X108', 'X109', 'X110', 'X111', 'X112',\n",
    "         'X113', 'X114', 'X115', 'X116', 'X117', 'X118', 'X119', 'X120', 'X121', 'X122', 'X123', 'X124', 'X125', 'X126', 'X127',\n",
    "         'X128', 'X129', 'X130', 'X131', 'X132', 'X133', 'X134', 'X135', 'X136', 'X137', 'X138', 'X139', 'X140', 'X141', 'X142',\n",
    "         'X143', 'X144', 'X145', 'X146', 'X147', 'X148', 'X149', 'X150', 'X151', 'X152', 'X153', 'X154', 'X155', 'X156', 'X157',\n",
    "         'X158', 'X159', 'X160', 'X161', 'X162', 'X163', 'X164', 'X165', 'X166', 'X167', 'X168', 'X169', 'X170', 'X171', 'X172',\n",
    "         'X173', 'X174', 'X175', 'X176', 'X177', 'X178', 'X179', 'X180', 'X181', 'X182', 'X183', 'X184', 'X185', 'X186', 'X187',\n",
    "         'X188', 'X189', 'X190', 'X191', 'X192', 'X193', 'X194', 'X195', 'X196', 'X197', 'X198', 'X199', 'X200', 'X201', 'X202',\n",
    "         'X203', 'X204', 'X205', 'X206', 'X207', 'X208', 'X209', 'X210', 'X211', 'X212', 'X213', 'X214', 'X215', 'X216', 'X217',\n",
    "         'X218', 'X219', 'X220', 'X221', 'X222', 'X223', 'X224', 'X225', 'X226', 'X227', 'X228', 'X229', 'X230', 'X231', 'X232',\n",
    "         'X233', 'X234', 'X235', 'X236', 'X237', 'X238', 'X239', 'X240', 'X241', 'X242', 'X243', 'X244', 'X245', 'X246', 'X247',\n",
    "         'X248', 'X249', 'X250', 'X251', 'X252', 'X253', 'X254', 'X255', 'X256', 'X257', 'X258', 'X259', 'X260', 'X261', 'X262',\n",
    "         'X263', 'X264', 'X265', 'X266', 'X267', 'X268', 'X269', 'X270', 'X271', 'X272', 'X273', 'X274', 'X275', 'X276', 'X277',\n",
    "         'X278', 'X279', 'X280', 'X281', 'X282', 'X283', 'X284', 'X285', 'X286', 'X287', 'X288', 'X289', 'X290', 'X291', 'X292',\n",
    "         'X293', 'X294', 'X295', 'X296', 'X297', 'X298', 'X299', 'X300', 'X301', 'X302', 'X303', 'X304', 'X305', 'X306', 'X307',\n",
    "         'X308', 'X309', 'X310', 'X311', 'X312', 'X313', 'X314', 'X315', 'X316', 'X317', 'X318', 'X319', 'X320', 'X321', 'X322',\n",
    "         'X323', 'X324', 'X225', 'X326', 'X327', 'X328', 'X329', 'X330', 'X331', 'X332', 'X333', 'X334', 'X335', 'X336', 'X337',\n",
    "         'X338', 'X339', 'X340', 'X341', 'X342', 'X343', 'X344', 'X345', 'X346', 'X347', 'X348', 'X349', 'X350', 'X351', 'X352',\n",
    "         'X353', 'X354', 'X355', 'X356', 'X357', 'X358', 'X359', 'X360', 'X361', 'X362', 'X363', 'X364', 'X365', 'X366', 'X367',\n",
    "         'X368', 'X369', 'X370', 'X371', 'X372', 'X373', 'X374', 'X375', 'X376', 'X377', 'X378', 'X379', 'X380', 'X381', 'X382',\n",
    "         'X383', 'X384', 'X385', 'X386', 'X387', 'X388', 'X389', 'X390', 'X391', 'X392', 'X393', 'X394', 'X395', 'X396', 'X397',\n",
    "         'X398', 'X399', 'X400', 'X401', 'X402', 'X403', 'X404', 'X405', 'X406', 'X407', 'X408', 'X409', 'X410', 'X411', 'X412',\n",
    "         'X413', 'X414', 'X415', 'X416', 'X417', 'X418', 'X419', 'X420', 'X421', 'X422', 'X423', 'X424', 'X425', 'X426', 'X427',\n",
    "         'X428', 'X429', 'X430', 'X431', 'X432', 'X433', 'X434', 'X435', 'X436', 'X437', 'X438', 'X439', 'X440', 'X441', 'X442',\n",
    "         'X443', 'X444', 'X445', 'X446', 'X447', 'X448', 'X449', 'X450', 'X451', 'X452', 'X453', 'X454', 'X455', 'X456', 'X457',\n",
    "         'X458', 'X459', 'X460', 'X461', 'X462', 'X463', 'X464', 'X465', 'X466', 'X467', 'X468', 'X469', 'X470', 'X471', 'X472',\n",
    "         'X473', 'X474', 'X475', 'X476', 'X477', 'X478', 'X479', 'X480', 'X481', 'X482', 'X483', 'X484', 'X485', 'X486', 'X487',\n",
    "         'X488', 'X489', 'X490', 'X491', 'X492', 'X493', 'X494', 'X495', 'X496', 'X497', 'X498', 'X499', 'X500', 'X501', 'X502',\n",
    "         'X503', 'X504', 'X505', 'X506', 'X507', 'X508', 'X509', 'X510', 'X511', 'X512', 'X513', 'X514', 'X515', 'X516', 'X517',\n",
    "         'X518', 'X519', 'X520', 'X521', 'X522', 'X523', 'X524', 'X525', 'X526', 'X527', 'X528', 'X529', 'X530', 'X531', 'X532',\n",
    "         'X533', 'X534', 'X535', 'X536', 'X537', 'X538', 'X539', 'X540', 'X541', 'X542', 'X543', 'X544', 'X545', 'X546', 'X547',\n",
    "         'X548', 'X549', 'X550', 'X551', 'X552', 'X553', 'X554', 'X555', 'X556', 'X557', 'X558', 'X559', 'X560', 'X561', 'X562',\n",
    "         'X563', 'X564', 'X565', 'X566', 'X567', 'X568', 'X569', 'X570', 'X571', 'X572', 'X573', 'X574', 'X575', 'X576', 'X577',\n",
    "         'X578', 'X579', 'X580', 'X581', 'X582', 'X583', 'X584', 'X585', 'X586', 'X587', 'X588', 'X589', 'X590', 'X591', 'X592',\n",
    "         'X593', 'X594', 'X595', 'X596', 'X597', 'X598', 'X599', 'X600', 'X601', 'X602', 'X603', 'X604', 'X605', 'X606', 'X607',\n",
    "         'X608', 'X609', 'X610', 'X611', 'X612', 'X613', 'X614', 'X615', 'X616', 'X617', 'X618', 'X619', 'X620', 'X621', 'X622',\n",
    "         'X623', 'X624', 'X625', 'X626', 'X627', 'X628', 'X629', 'X630', 'X631', 'X632', 'X633', 'X634', 'X635', 'X636', 'X637',\n",
    "         'X638', 'X639', 'X640', 'X641', 'X642', 'X643', 'X644', 'X645', 'X646', 'X647', 'X648', 'X649', 'X650', 'X651', 'X652',\n",
    "         'X653', 'X654', 'X655', 'X656', 'X657', 'X658', 'X659', 'X660', 'X661', 'X662', 'X663', 'X664', 'X665', 'X666', 'X667',\n",
    "         'X668', 'X669', 'X670', 'X671', 'X672', 'X673', 'X674', 'X675', 'X676', 'X677', 'X678', 'X679', 'X680', 'X681', 'X682',\n",
    "         'X683', 'X684', 'X685', 'X686', 'X687', 'X688', 'X689', 'X690', 'X691', 'X692', 'X693', 'X694', 'X695', 'X696', 'X697',\n",
    "         'X698', 'X699', 'X700', 'X701', 'X702', 'X703', 'X704', 'X705', 'X706', 'X707', 'X708', 'X709', 'X710', 'X711', 'X712',\n",
    "         'X713', 'X714', 'X715', 'X716', 'X717', 'X718', 'X719', 'X720']]\n",
    "y = data['Y']\n",
    "#.astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5623719e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "818"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2274617",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6488/1775580783.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78903ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b1f78fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 - 4s - loss: 3.4198 - val_loss: 3.0476 - 4s/epoch - 298ms/step\n",
      "Epoch 2/100\n",
      "12/12 - 0s - loss: 3.2341 - val_loss: 2.9796 - 110ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "12/12 - 0s - loss: 3.1732 - val_loss: 2.9103 - 89ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "12/12 - 0s - loss: 3.1107 - val_loss: 2.8395 - 84ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "12/12 - 0s - loss: 3.0473 - val_loss: 2.7689 - 85ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "12/12 - 0s - loss: 2.9837 - val_loss: 2.7028 - 87ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "12/12 - 0s - loss: 2.9355 - val_loss: 2.6634 - 81ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "12/12 - 0s - loss: 2.9020 - val_loss: 2.6278 - 81ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "12/12 - 0s - loss: 2.8704 - val_loss: 2.5926 - 81ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "12/12 - 0s - loss: 2.8386 - val_loss: 2.5569 - 84ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "12/12 - 0s - loss: 2.8063 - val_loss: 2.5205 - 83ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "12/12 - 0s - loss: 2.7733 - val_loss: 2.4834 - 99ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "12/12 - 0s - loss: 2.7397 - val_loss: 2.4456 - 85ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "12/12 - 0s - loss: 2.7055 - val_loss: 2.4072 - 84ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "12/12 - 0s - loss: 2.6715 - val_loss: 2.3758 - 90ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "12/12 - 0s - loss: 2.6468 - val_loss: 2.3537 - 92ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "12/12 - 0s - loss: 2.6255 - val_loss: 2.3327 - 84ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "12/12 - 0s - loss: 2.6049 - val_loss: 2.3133 - 88ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "12/12 - 0s - loss: 2.5851 - val_loss: 2.2943 - 87ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "12/12 - 0s - loss: 2.5651 - val_loss: 2.2752 - 97ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "12/12 - 0s - loss: 2.5451 - val_loss: 2.2558 - 85ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "12/12 - 0s - loss: 2.5250 - val_loss: 2.2366 - 85ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "12/12 - 0s - loss: 2.5049 - val_loss: 2.2171 - 87ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "12/12 - 0s - loss: 2.4846 - val_loss: 2.1977 - 86ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "12/12 - 0s - loss: 2.4647 - val_loss: 2.1850 - 87ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "12/12 - 0s - loss: 2.4579 - val_loss: 2.1835 - 90ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "12/12 - 0s - loss: 2.4553 - val_loss: 2.1825 - 93ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "12/12 - 0s - loss: 2.4534 - val_loss: 2.1816 - 87ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "12/12 - 0s - loss: 2.4516 - val_loss: 2.1806 - 102ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "12/12 - 0s - loss: 2.4499 - val_loss: 2.1797 - 97ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "12/12 - 0s - loss: 2.4481 - val_loss: 2.1788 - 88ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "12/12 - 0s - loss: 2.4464 - val_loss: 2.1779 - 85ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "12/12 - 0s - loss: 2.4446 - val_loss: 2.1769 - 85ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "12/12 - 0s - loss: 2.4428 - val_loss: 2.1760 - 96ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "12/12 - 0s - loss: 2.4410 - val_loss: 2.1750 - 83ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "12/12 - 0s - loss: 2.4391 - val_loss: 2.1740 - 79ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "12/12 - 0s - loss: 2.4377 - val_loss: 2.1734 - 87ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "12/12 - 0s - loss: 2.4367 - val_loss: 2.1729 - 87ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "12/12 - 0s - loss: 2.4358 - val_loss: 2.1724 - 75ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "12/12 - 0s - loss: 2.4349 - val_loss: 2.1719 - 83ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "12/12 - 0s - loss: 2.4341 - val_loss: 2.1714 - 98ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "12/12 - 0s - loss: 2.4332 - val_loss: 2.1709 - 111ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "12/12 - 0s - loss: 2.4323 - val_loss: 2.1703 - 75ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "12/12 - 0s - loss: 2.4315 - val_loss: 2.1706 - 78ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "12/12 - 0s - loss: 2.4308 - val_loss: 2.1708 - 86ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "12/12 - 0s - loss: 2.4302 - val_loss: 2.1711 - 86ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "12/12 - 0s - loss: 2.4295 - val_loss: 2.1714 - 87ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "12/12 - 0s - loss: 2.4289 - val_loss: 2.1716 - 91ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "12/12 - 0s - loss: 2.4282 - val_loss: 2.1719 - 80ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "12/12 - 0s - loss: 2.4276 - val_loss: 2.1721 - 81ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "12/12 - 0s - loss: 2.4269 - val_loss: 2.1724 - 82ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "12/12 - 0s - loss: 2.4262 - val_loss: 2.1727 - 83ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "12/12 - 0s - loss: 2.4255 - val_loss: 2.1730 - 86ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "12/12 - 0s - loss: 2.4249 - val_loss: 2.1732 - 84ms/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "12/12 - 0s - loss: 2.4242 - val_loss: 2.1735 - 82ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "12/12 - 0s - loss: 2.4235 - val_loss: 2.1738 - 82ms/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "12/12 - 0s - loss: 2.4228 - val_loss: 2.1741 - 85ms/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "12/12 - 0s - loss: 2.4221 - val_loss: 2.1744 - 80ms/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "12/12 - 0s - loss: 2.4214 - val_loss: 2.1747 - 80ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "12/12 - 0s - loss: 2.4207 - val_loss: 2.1750 - 80ms/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "12/12 - 0s - loss: 2.4201 - val_loss: 2.1754 - 83ms/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "12/12 - 0s - loss: 2.4197 - val_loss: 2.1746 - 84ms/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "12/12 - 0s - loss: 2.4198 - val_loss: 2.1747 - 81ms/epoch - 7ms/step\n",
      "Epoch 64/100\n",
      "12/12 - 0s - loss: 2.4200 - val_loss: 2.1741 - 85ms/epoch - 7ms/step\n",
      "Epoch 65/100\n",
      "12/12 - 0s - loss: 2.4198 - val_loss: 2.1739 - 87ms/epoch - 7ms/step\n",
      "Epoch 66/100\n",
      "12/12 - 0s - loss: 2.4195 - val_loss: 2.1748 - 80ms/epoch - 7ms/step\n",
      "Epoch 67/100\n",
      "12/12 - 0s - loss: 2.4193 - val_loss: 2.1734 - 84ms/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "12/12 - 0s - loss: 2.4196 - val_loss: 2.1733 - 77ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "12/12 - 0s - loss: 2.4192 - val_loss: 2.1734 - 83ms/epoch - 7ms/step\n",
      "Epoch 70/100\n",
      "12/12 - 0s - loss: 2.4189 - val_loss: 2.1730 - 77ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "12/12 - 0s - loss: 2.4189 - val_loss: 2.1732 - 76ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "12/12 - 0s - loss: 2.4186 - val_loss: 2.1726 - 84ms/epoch - 7ms/step\n",
      "Epoch 73/100\n",
      "12/12 - 0s - loss: 2.4188 - val_loss: 2.1725 - 79ms/epoch - 7ms/step\n",
      "Epoch 74/100\n",
      "12/12 - 0s - loss: 2.4188 - val_loss: 2.1720 - 83ms/epoch - 7ms/step\n",
      "Epoch 75/100\n",
      "12/12 - 0s - loss: 2.4187 - val_loss: 2.1719 - 83ms/epoch - 7ms/step\n",
      "Epoch 76/100\n",
      "12/12 - 0s - loss: 2.4188 - val_loss: 2.1716 - 79ms/epoch - 7ms/step\n",
      "Epoch 77/100\n",
      "12/12 - 0s - loss: 2.4185 - val_loss: 2.1714 - 77ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "12/12 - 0s - loss: 2.4185 - val_loss: 2.1712 - 84ms/epoch - 7ms/step\n",
      "Epoch 79/100\n",
      "12/12 - 0s - loss: 2.4182 - val_loss: 2.1712 - 84ms/epoch - 7ms/step\n",
      "Epoch 80/100\n",
      "12/12 - 0s - loss: 2.4184 - val_loss: 2.1706 - 79ms/epoch - 7ms/step\n",
      "Epoch 81/100\n",
      "12/12 - 0s - loss: 2.4182 - val_loss: 2.1705 - 89ms/epoch - 7ms/step\n",
      "Epoch 82/100\n",
      "12/12 - 0s - loss: 2.4180 - val_loss: 2.1711 - 110ms/epoch - 9ms/step\n",
      "Epoch 83/100\n",
      "12/12 - 0s - loss: 2.4177 - val_loss: 2.1699 - 77ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "12/12 - 0s - loss: 2.4180 - val_loss: 2.1698 - 77ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "12/12 - 0s - loss: 2.4176 - val_loss: 2.1702 - 81ms/epoch - 7ms/step\n",
      "Epoch 86/100\n",
      "12/12 - 0s - loss: 2.4173 - val_loss: 2.1694 - 85ms/epoch - 7ms/step\n",
      "Epoch 87/100\n",
      "12/12 - 0s - loss: 2.4175 - val_loss: 2.1694 - 85ms/epoch - 7ms/step\n",
      "Epoch 88/100\n",
      "12/12 - 0s - loss: 2.4174 - val_loss: 2.1690 - 80ms/epoch - 7ms/step\n",
      "Epoch 89/100\n",
      "12/12 - 0s - loss: 2.4173 - val_loss: 2.1690 - 85ms/epoch - 7ms/step\n",
      "Epoch 90/100\n",
      "12/12 - 0s - loss: 2.4173 - val_loss: 2.1686 - 81ms/epoch - 7ms/step\n",
      "Epoch 91/100\n",
      "12/12 - 0s - loss: 2.4170 - val_loss: 2.1686 - 86ms/epoch - 7ms/step\n",
      "Epoch 92/100\n",
      "12/12 - 0s - loss: 2.4170 - val_loss: 2.1681 - 83ms/epoch - 7ms/step\n",
      "Epoch 93/100\n",
      "12/12 - 0s - loss: 2.4169 - val_loss: 2.1681 - 90ms/epoch - 7ms/step\n",
      "Epoch 94/100\n",
      "12/12 - 0s - loss: 2.4169 - val_loss: 2.1677 - 83ms/epoch - 7ms/step\n",
      "Epoch 95/100\n",
      "12/12 - 0s - loss: 2.4166 - val_loss: 2.1677 - 83ms/epoch - 7ms/step\n",
      "Epoch 96/100\n",
      "12/12 - 0s - loss: 2.4166 - val_loss: 2.1672 - 89ms/epoch - 7ms/step\n",
      "Epoch 97/100\n",
      "12/12 - 0s - loss: 2.4165 - val_loss: 2.1672 - 121ms/epoch - 10ms/step\n",
      "Epoch 98/100\n",
      "12/12 - 0s - loss: 2.4165 - val_loss: 2.1669 - 85ms/epoch - 7ms/step\n",
      "Epoch 99/100\n",
      "12/12 - 0s - loss: 2.4162 - val_loss: 2.1669 - 81ms/epoch - 7ms/step\n",
      "Epoch 100/100\n",
      "12/12 - 0s - loss: 2.4162 - val_loss: 2.1664 - 85ms/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# สร้าง LSTM network ด้วย library Keras โดยกำหนดขนาด hidden layer(50) และ shape ของข้อมูล input(#rows x #features)\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "# สร้าง hidden layer ตามขนาด output หรือ จำนวนวันที่ต้องการ forecast (3) \n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "# train โมเดล และเก็บ log\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=72, validation_data=(X_test, y_test), verbose=2, shuffle=False)\n",
    "\n",
    "# พล็อตค่า train&test loss\n",
    "#pyplot.plot(history.history['loss'], label='train')\n",
    "#pyplot.plot(history.history['val_loss'], label='test')\n",
    "#pyplot.legend()\n",
    "#pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d01c83fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 - 3s - loss: 2.4169 - val_loss: 2.1657 - 3s/epoch - 289ms/step\n",
      "Epoch 2/100\n",
      "12/12 - 0s - loss: 2.4165 - val_loss: 2.1657 - 81ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "12/12 - 0s - loss: 2.4161 - val_loss: 2.1660 - 73ms/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "12/12 - 0s - loss: 2.4158 - val_loss: 2.1654 - 84ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "12/12 - 0s - loss: 2.4158 - val_loss: 2.1654 - 84ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "12/12 - 0s - loss: 2.4157 - val_loss: 2.1650 - 82ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "12/12 - 0s - loss: 2.4155 - val_loss: 2.1651 - 92ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "12/12 - 0s - loss: 2.4154 - val_loss: 2.1645 - 84ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "12/12 - 0s - loss: 2.4153 - val_loss: 2.1645 - 108ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "12/12 - 0s - loss: 2.4153 - val_loss: 2.1642 - 84ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "12/12 - 0s - loss: 2.4150 - val_loss: 2.1642 - 83ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "12/12 - 0s - loss: 2.4150 - val_loss: 2.1636 - 83ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "12/12 - 0s - loss: 2.4149 - val_loss: 2.1637 - 89ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "12/12 - 0s - loss: 2.4149 - val_loss: 2.1633 - 86ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "12/12 - 0s - loss: 2.4146 - val_loss: 2.1633 - 83ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "12/12 - 0s - loss: 2.4146 - val_loss: 2.1628 - 100ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "12/12 - 0s - loss: 2.4145 - val_loss: 2.1628 - 83ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "12/12 - 0s - loss: 2.4145 - val_loss: 2.1624 - 87ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "12/12 - 0s - loss: 2.4142 - val_loss: 2.1624 - 93ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "12/12 - 0s - loss: 2.4142 - val_loss: 2.1619 - 85ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "12/12 - 0s - loss: 2.4141 - val_loss: 2.1619 - 76ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "12/12 - 0s - loss: 2.4141 - val_loss: 2.1615 - 85ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "12/12 - 0s - loss: 2.4138 - val_loss: 2.1616 - 82ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "12/12 - 0s - loss: 2.4138 - val_loss: 2.1610 - 79ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "12/12 - 0s - loss: 2.4137 - val_loss: 2.1611 - 90ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "12/12 - 0s - loss: 2.4137 - val_loss: 2.1607 - 82ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "12/12 - 0s - loss: 2.4134 - val_loss: 2.1607 - 79ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "12/12 - 0s - loss: 2.4133 - val_loss: 2.1602 - 83ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "12/12 - 0s - loss: 2.4133 - val_loss: 2.1602 - 85ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "12/12 - 0s - loss: 2.4133 - val_loss: 2.1598 - 80ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "12/12 - 0s - loss: 2.4130 - val_loss: 2.1598 - 82ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "12/12 - 0s - loss: 2.4129 - val_loss: 2.1593 - 87ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "12/12 - 0s - loss: 2.4129 - val_loss: 2.1593 - 91ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "12/12 - 0s - loss: 2.4128 - val_loss: 2.1589 - 84ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "12/12 - 0s - loss: 2.4126 - val_loss: 2.1589 - 82ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "12/12 - 0s - loss: 2.4125 - val_loss: 2.1584 - 91ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "12/12 - 0s - loss: 2.4124 - val_loss: 2.1584 - 79ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "12/12 - 0s - loss: 2.4124 - val_loss: 2.1580 - 81ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "12/12 - 0s - loss: 2.4122 - val_loss: 2.1581 - 88ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "12/12 - 0s - loss: 2.4121 - val_loss: 2.1575 - 78ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "12/12 - 0s - loss: 2.4120 - val_loss: 2.1576 - 86ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "12/12 - 0s - loss: 2.4120 - val_loss: 2.1572 - 92ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "12/12 - 0s - loss: 2.4118 - val_loss: 2.1572 - 83ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "12/12 - 0s - loss: 2.4119 - val_loss: 2.1568 - 86ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "12/12 - 0s - loss: 2.4115 - val_loss: 2.1568 - 88ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "12/12 - 0s - loss: 2.4117 - val_loss: 2.1561 - 81ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "12/12 - 0s - loss: 2.4116 - val_loss: 2.1560 - 78ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "12/12 - 0s - loss: 2.4113 - val_loss: 2.1564 - 99ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "12/12 - 0s - loss: 2.4108 - val_loss: 2.1557 - 84ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "12/12 - 0s - loss: 2.4110 - val_loss: 2.1558 - 77ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "12/12 - 0s - loss: 2.4111 - val_loss: 2.1549 - 77ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "12/12 - 0s - loss: 2.4113 - val_loss: 2.1548 - 81ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "12/12 - 0s - loss: 2.4109 - val_loss: 2.1551 - 83ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "12/12 - 0s - loss: 2.4110 - val_loss: 2.1544 - 86ms/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "12/12 - 0s - loss: 2.4107 - val_loss: 2.1543 - 82ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "12/12 - 0s - loss: 2.4104 - val_loss: 2.1552 - 83ms/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "12/12 - 0s - loss: 2.4099 - val_loss: 2.1541 - 85ms/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "12/12 - 0s - loss: 2.4103 - val_loss: 2.1539 - 77ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "12/12 - 0s - loss: 2.4100 - val_loss: 2.1538 - 84ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "12/12 - 0s - loss: 2.4101 - val_loss: 2.1531 - 80ms/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "12/12 - 0s - loss: 2.4101 - val_loss: 2.1531 - 89ms/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "12/12 - 0s - loss: 2.4099 - val_loss: 2.1530 - 81ms/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "12/12 - 0s - loss: 2.4098 - val_loss: 2.1527 - 78ms/epoch - 7ms/step\n",
      "Epoch 64/100\n",
      "12/12 - 0s - loss: 2.4094 - val_loss: 2.1537 - 79ms/epoch - 7ms/step\n",
      "Epoch 65/100\n",
      "12/12 - 0s - loss: 2.4094 - val_loss: 2.1519 - 91ms/epoch - 8ms/step\n",
      "Epoch 66/100\n",
      "12/12 - 0s - loss: 2.4098 - val_loss: 2.1519 - 77ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "12/12 - 0s - loss: 2.4093 - val_loss: 2.1529 - 88ms/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "12/12 - 0s - loss: 2.4090 - val_loss: 2.1513 - 83ms/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "12/12 - 0s - loss: 2.4094 - val_loss: 2.1513 - 87ms/epoch - 7ms/step\n",
      "Epoch 70/100\n",
      "12/12 - 0s - loss: 2.4090 - val_loss: 2.1515 - 81ms/epoch - 7ms/step\n",
      "Epoch 71/100\n",
      "12/12 - 0s - loss: 2.4086 - val_loss: 2.1510 - 92ms/epoch - 8ms/step\n",
      "Epoch 72/100\n",
      "12/12 - 0s - loss: 2.4086 - val_loss: 2.1512 - 85ms/epoch - 7ms/step\n",
      "Epoch 73/100\n",
      "12/12 - 0s - loss: 2.4083 - val_loss: 2.1506 - 86ms/epoch - 7ms/step\n",
      "Epoch 74/100\n",
      "12/12 - 0s - loss: 2.4085 - val_loss: 2.1505 - 85ms/epoch - 7ms/step\n",
      "Epoch 75/100\n",
      "12/12 - 0s - loss: 2.4086 - val_loss: 2.1499 - 79ms/epoch - 7ms/step\n",
      "Epoch 76/100\n",
      "12/12 - 0s - loss: 2.4085 - val_loss: 2.1499 - 77ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "12/12 - 0s - loss: 2.4086 - val_loss: 2.1495 - 87ms/epoch - 7ms/step\n",
      "Epoch 78/100\n",
      "12/12 - 0s - loss: 2.4083 - val_loss: 2.1494 - 79ms/epoch - 7ms/step\n",
      "Epoch 79/100\n",
      "12/12 - 0s - loss: 2.4081 - val_loss: 2.1495 - 84ms/epoch - 7ms/step\n",
      "Epoch 80/100\n",
      "12/12 - 0s - loss: 2.4079 - val_loss: 2.1487 - 82ms/epoch - 7ms/step\n",
      "Epoch 81/100\n",
      "12/12 - 0s - loss: 2.4081 - val_loss: 2.1487 - 81ms/epoch - 7ms/step\n",
      "Epoch 82/100\n",
      "12/12 - 0s - loss: 2.4078 - val_loss: 2.1488 - 83ms/epoch - 7ms/step\n",
      "Epoch 83/100\n",
      "12/12 - 0s - loss: 2.4078 - val_loss: 2.1482 - 94ms/epoch - 8ms/step\n",
      "Epoch 84/100\n",
      "12/12 - 0s - loss: 2.4077 - val_loss: 2.1482 - 74ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "12/12 - 0s - loss: 2.4073 - val_loss: 2.1475 - 80ms/epoch - 7ms/step\n",
      "Epoch 86/100\n",
      "12/12 - 0s - loss: 2.4072 - val_loss: 2.1473 - 87ms/epoch - 7ms/step\n",
      "Epoch 87/100\n",
      "12/12 - 0s - loss: 2.4069 - val_loss: 2.1472 - 78ms/epoch - 7ms/step\n",
      "Epoch 88/100\n",
      "12/12 - 0s - loss: 2.4069 - val_loss: 2.1465 - 82ms/epoch - 7ms/step\n",
      "Epoch 89/100\n",
      "12/12 - 0s - loss: 2.4069 - val_loss: 2.1465 - 90ms/epoch - 7ms/step\n",
      "Epoch 90/100\n",
      "12/12 - 0s - loss: 2.4068 - val_loss: 2.1464 - 79ms/epoch - 7ms/step\n",
      "Epoch 91/100\n",
      "12/12 - 0s - loss: 2.4066 - val_loss: 2.1461 - 81ms/epoch - 7ms/step\n",
      "Epoch 92/100\n",
      "12/12 - 0s - loss: 2.4063 - val_loss: 2.1471 - 89ms/epoch - 7ms/step\n",
      "Epoch 93/100\n",
      "12/12 - 0s - loss: 2.4062 - val_loss: 2.1453 - 79ms/epoch - 7ms/step\n",
      "Epoch 94/100\n",
      "12/12 - 0s - loss: 2.4066 - val_loss: 2.1453 - 84ms/epoch - 7ms/step\n",
      "Epoch 95/100\n",
      "12/12 - 0s - loss: 2.4062 - val_loss: 2.1465 - 88ms/epoch - 7ms/step\n",
      "Epoch 96/100\n",
      "12/12 - 0s - loss: 2.4060 - val_loss: 2.1447 - 85ms/epoch - 7ms/step\n",
      "Epoch 97/100\n",
      "12/12 - 0s - loss: 2.4062 - val_loss: 2.1447 - 83ms/epoch - 7ms/step\n",
      "Epoch 98/100\n",
      "12/12 - 0s - loss: 2.4059 - val_loss: 2.1448 - 86ms/epoch - 7ms/step\n",
      "Epoch 99/100\n",
      "12/12 - 0s - loss: 2.4059 - val_loss: 2.1442 - 79ms/epoch - 7ms/step\n",
      "Epoch 100/100\n",
      "12/12 - 0s - loss: 2.4058 - val_loss: 2.1442 - 84ms/epoch - 7ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s - loss: 2.1442 - 38ms/epoch - 5ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable float object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6488/1971519422.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m72\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable float object"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# compile the model\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit the model\n",
    "#history = model.fit(X_train, y_train, validation_split=0.3, epochs=10, verbose=2)\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=72, validation_data=(X_test, y_test), verbose=2, shuffle=False)\n",
    "# evaluate the model\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffa9321f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-48.64878845214844"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8f838ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2487804889678955"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94a8338a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ef7fdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2792adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45bc9aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 1s - 669ms/epoch - 335ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6488/986332182.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test, batch_size=200, verbose=2)\n",
    "report = classification_report(Y_test, y_pred.round())\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "087eb685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 2.1664\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable float object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6488/4146528936.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable float object"
     ]
    }
   ],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e8d459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
